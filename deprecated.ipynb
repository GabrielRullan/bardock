{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from mino_repo.mino_repo_class import MinoRepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "class MinoRepo():\n",
    "    def __init__(self, fact_table):\n",
    "        self.fact_table = fact_table\n",
    "        self.fields = fact_table.columns.tolist()\n",
    "        self.fact_fields = fact_table.columns.tolist()\n",
    "        self.dim_fields = {}\n",
    "        self.foreignKeys = {}\n",
    "        self.tables = [fact_table]\n",
    "        self.master_tables = {}\n",
    "        self.master_tree = {}\n",
    "        self.master_tables_names = []\n",
    "\n",
    "    def find_wrong_stucture(self):\n",
    "        __test_duplicates = []\n",
    "        __right_dim_fields = []\n",
    "        for __temp_dim_table in self.master_tables.keys():\n",
    "            __test_duplicates += self.master_tables[__temp_dim_table].columns.tolist()\n",
    "            __test_duplicates += [self.master_tables[__temp_dim_table].index.name]\n",
    "        for i in __test_duplicates:\n",
    "            if __test_duplicates.count(i) > 1:\n",
    "                print('there are duplicated fields')\n",
    "                print('please run a reshape_dims()')\n",
    "                return True\n",
    "        # now we make sure we have all fields in the attributesc\n",
    "        # we do not include the foreign keys\n",
    "        __right_dim_fields = [x for x in __test_duplicates if x.find('__FK__') == -1]\n",
    "        __current_dim_fields = list(self.dim_fields.keys())\n",
    "        # we sort them\n",
    "        __right_dim_fields.sort()\n",
    "        __current_dim_fields.sort()\n",
    "        # now compare them\n",
    "        if not __right_dim_fields == __current_dim_fields:\n",
    "            print('current structure is')\n",
    "            print(__right_dim_fields)\n",
    "            print('according to the attributes the structure should be')\n",
    "            print(__current_dim_fields)\n",
    "            print('please run a reshape_dims()')\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def reshape_dims(self):\n",
    "        self.dim_fields = {}\n",
    "\n",
    "        for __temp_dim_table_name in self.master_tables_names:\n",
    "            __temp_dim_table = self.master_tables[__temp_dim_table_name]\n",
    "            __columns_list = __temp_dim_table.columns.tolist()\n",
    "            for __column_name in __columns_list:\n",
    "                self.dim_fields[__column_name] = __temp_dim_table_name\n",
    "\n",
    "    def create_dim(self, fields_to_move, dim_table_name, debug=False):\n",
    "        if debug: print(0)\n",
    "        __subtable__ = self.fact_table.ix[:, fields_to_move]\n",
    "        foreign_key = self.__get__next_foreign_key__()\n",
    "        if isinstance(fields_to_move, list):\n",
    "            __aux_unique_values = __subtable__.drop_duplicates()\n",
    "            if debug: print(0)\n",
    "            __aux_unique_values = __aux_unique_values.reset_index(drop=True)\n",
    "            self.fact_table = pandas.merge(self.fact_table, __aux_unique_values, on=fields_to_move, how='left')\n",
    "        else:\n",
    "            # for  a single dim we use lists so that we can then use map (much faster than merge)\n",
    "            __aux_unique_values = __subtable__.unique().tolist()\n",
    "            if debug: print(0)\n",
    "            self.fact_table[foreign_key] = self.fact_table[fields_to_move].map(lambda x: __aux_unique_values.index(x))\n",
    "            __aux_unique_values = pandas.DataFrame(__aux_unique_values, columns=[fields_to_move])\n",
    "        if debug: print(0)\n",
    "        self.fact_table = self.fact_table.drop(fields_to_move, axis=1)\n",
    "        __aux_unique_values[foreign_key] = __aux_unique_values.index.map(lambda x: int(x))\n",
    "        __temp_dim_table__ = __aux_unique_values.set_index(foreign_key, drop=True)\n",
    "        foreign_key = self.__get__next_foreign_key__()\n",
    "        if debug: print(0)\n",
    "        # Adding to lists\n",
    "        # dim_table\n",
    "        self.master_tables[dim_table_name] = __temp_dim_table__\n",
    "        self.master_tables_names.append(dim_table_name)\n",
    "        # foreign_key\n",
    "        if debug: print(0)\n",
    "        if len(self.foreignKeys) == 0:\n",
    "            self.foreignKeys[foreign_key] = dim_table_name\n",
    "        elif foreign_key in self.foreignKeys:\n",
    "            self.foreignKeys[foreign_key].append(dim_table_name)\n",
    "            print('There seems to be an issue with shared foreign keys')\n",
    "        else:\n",
    "            self.foreignKeys[foreign_key] = dim_table_name\n",
    "        # relation with fields\n",
    "        # field lists\n",
    "        self.master_tree[dim_table_name] = {'parent':'','child':[]}\n",
    "        if isinstance(fields_to_move, list):\n",
    "            for _field_to_move in fields_to_move:\n",
    "                self.dim_fields[_field_to_move] = dim_table_name\n",
    "                self.fact_fields.remove(_field_to_move)\n",
    "        else:\n",
    "            self.dim_fields[fields_to_move] = dim_table_name\n",
    "            self.fact_fields.remove(fields_to_move)\n",
    "            \n",
    "        \n",
    "\n",
    "\n",
    "    def __get__next_foreign_key__(self):\n",
    "        prefix_foreign_key = '__FK__'\n",
    "        if len(self.foreignKeys.keys()) > 0:\n",
    "            __list__ = []\n",
    "            for _l_ in self.foreignKeys.keys():\n",
    "                __list__.append(_l_)\n",
    "            __list__.sort(reverse=True)\n",
    "            __last_key__ = __list__[0]\n",
    "            foreign_key_next = __last_key__.replace(prefix_foreign_key, '')\n",
    "            if foreign_key_next.isnumeric():\n",
    "                foreign_key_next = int(foreign_key_next) + 1\n",
    "                return prefix_foreign_key + str(foreign_key_next).zfill(2)\n",
    "        foreign_key_next = 1\n",
    "        return prefix_foreign_key + str(foreign_key_next).zfill(2)\n",
    "\n",
    "    def filter_facts(self, filter_value, filter_field, fields_to_load = []):\n",
    "        if filter_field.__class__ == list:\n",
    "            print('Function not yet avalaible, please filter a single dim')\n",
    "        return self.__filter_one_dim__(filter_value, filter_field, dim_fields_to_load = fields_to_load)\n",
    "\n",
    "    def __filter_one_dim__(self, filter_value, filter_field, negative=False, dim_fields_to_load = []):\n",
    "        filter_table_name = self.dim_fields[filter_field]\n",
    "        filter_table = self.master_tables[filter_table_name]\n",
    "        # We extract the foreign keys of the table\n",
    "        # First we get the names\n",
    "        #######right now we only consider one index per table\n",
    "        _foreign_key = filter_table.index.name\n",
    "        # Now we get the submatix that has the foreign keys as columns and the rows of the value we got\n",
    "        if negative:\n",
    "            index_filter = filter_table.loc[filter_table[filter_field] != filter_value].index\n",
    "        else:\n",
    "            index_filter = filter_table.loc[filter_table[filter_field] == filter_value].index\n",
    "        filtered_list = []\n",
    "        fact_fields_to_load_list = self.fact_fields\n",
    "        \n",
    "        if len(dim_fields_to_load) > 0:      \n",
    "            fact_fields_to_load_list.append(_foreign_key)\n",
    "        \n",
    "        fact_fields_to_load = chr(34) + '\" , \"'.join(fact_fields_to_load_list) + chr(34)    \n",
    "        result = self.fact_table.loc[\n",
    "                                    self.fact_table[_foreign_key].map(lambda x: x in index_filter),\n",
    "                                    eval(fact_fields_to_load)]\n",
    "        result = result.join(filter_table[dim_fields_to_load],how='left')\n",
    "        return result\n",
    "    \n",
    "    def create_dim2(self,fields_to_move,dim_table_name):\n",
    "        if isinstance(fields_to_move, list):\n",
    "            dim_table_origin_name = self.dim_fields[fields_to_move[0]]\n",
    "            for element in fields_to_move:\n",
    "                if dim_table_origin_name != self.dim_fields[element]:\n",
    "                    print('Error: Dimensions from multiple origins')\n",
    "                    return False\n",
    "                \n",
    "            dim_table_origin = self.master_tables[dim_table_origin_name]\n",
    "            __subtable__ = dim_table_origin.ix[:, fields_to_move]\n",
    "            foreign_key = self.__get__next_foreign_key__()\n",
    "            __aux_unique_values = __subtable__.drop_duplicates()\n",
    "            __aux_unique_values = __aux_unique_values.reset_index(drop = True)\n",
    "            __aux_unique_values[foreign_key] = __aux_unique_values.index.map(lambda x: int(x))\n",
    "\n",
    "            result = dim_table_origin.join(__aux_unique_values[foreign_key], \n",
    "                                            on=fields_to_move, how='left', lsuffix = '__drop__l')\n",
    "            _l_todrop = [i for i in result.columns if \"__drop__\" in i]\n",
    "            if len(_l_todrop):\n",
    "                result = result.drop(_l_todrop, axis = 1)\n",
    "        else:\n",
    "            dim_table_origin_name = self.dim_fields[fields_to_move]\n",
    "            dim_table_origin = self.master_tables[dim_table_origin_name]\n",
    "            __subtable__ = dim_table_origin.ix[:, fields_to_move]\n",
    "            __aux_unique_values = __subtable__.unique().tolist()\n",
    "            \n",
    "            dim_table_origin[foreign_key] = dim_table_origin[fields_to_move].map(lambda x: __aux_unique_values.index(x))\n",
    "            __aux_unique_values = pandas.DataFrame(__aux_unique_values, columns=[fields_to_move])\n",
    "            __aux_unique_values[foreign_key] = __aux_unique_values.index.map(lambda x: int(x))\n",
    "            \n",
    "            result = dim_table_origin\n",
    "            \n",
    "        result = result.drop(fields_to_move, axis = 1)\n",
    "        __aux_unique_values = __aux_unique_values.set_index(foreign_key)\n",
    "\n",
    "\n",
    "        self.master_tables[dim_table_name] = __aux_unique_values\n",
    "        self.master_tables[dim_table_origin_name] = result\n",
    "        self.master_tables_names.append(dim_table_name)\n",
    "        \n",
    "        self.master_tree[dim_table_name] = {'parent':dim_table_origin_name,'child':[]}\n",
    "        self.master_tree[dim_table_origin_name]['child'].append(dim_table_name)\n",
    "        \n",
    "        self.reshape_dims()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'fact_table'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-454b34537ccd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mMinoRepo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'fact_table'"
     ]
    }
   ],
   "source": [
    "MinoRepo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "zfile = '../../forecasting/data/full_data_with_weather'\n",
    "partial = True\n",
    "zcols = [1,2,3,7,8,9,10]\n",
    "if partial:\n",
    "    _nrows = 10**3\n",
    "    panda_readed = pandas.read_csv(zfile, usecols = zcols , nrows= _nrows)\n",
    "else:\n",
    "    panda_readed = pandas.read_csv(zfile, usecols = zcols)\n",
    "bb = MinoRepo(panda_readed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_fields_to_move = 'date'\n",
    "dim_table_name = 'dim_time'\n",
    "bb.create_dim(_fields_to_move, dim_table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb.master_tables['dim_time']['date'] = pandas.to_datetime(bb.master_tables['dim_time']['date'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "bb.master_tables['dim_time']['rDate'] = bb.master_tables['dim_time']['date'].map(lambda x: x.date())\n",
    "bb.master_tables['dim_time']['hour'] = bb.master_tables['dim_time']['date'].map(lambda x: x.hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb.reshape_dims()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_table_name = 'dim_hour'\n",
    "fields_to_move = ['hour']\n",
    "bb.create_dim2(fields_to_move,dim_table_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb.master_tables_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb.master_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fets = bb.filter_facts('2015-09-28','date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = bb.master_tables['dim_time'][bb.master_tables['dim_time'].index==23]\n",
    "dim2 = bb.master_tables['dim_hour'][bb.master_tables['dim_hour'].index == 23]\n",
    "dim_mix = dim.join(dim2, how = 'right')\n",
    "fets.join(dim_mix[['date','hour']],how='left', lsuffix = '_l')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lowest_dim = 'hour'\n",
    "dim_value = 0\n",
    "\n",
    "\n",
    "lowest_table_name = bb.dim_fields[lowest_dim]\n",
    "lowest_table = bb.master_tables[lowest_table_name]\n",
    "_subtable1_ = lowest_table[lowest_table[lowest_dim] == dim_value]\n",
    "parent = bb.master_tree[lowest_table_name]['parent']\n",
    "while len(parent)>0:\n",
    "    _subtable2_ = bb.master_tables[parent]\n",
    "    _subtable2_ = _subtable2_[_subtable2_[_subtable1_.index.name].isin(_subtable1_.index)]\n",
    "    _subtable_ = _subtable2_.join(_subtable1_, how='right', on = _subtable1_.index.name)\n",
    "    _subtable_ = _subtable_.drop(_subtable1_.index.name, axis = 1)\n",
    "    _list_K = _subtable2_.index.tolist()\n",
    "    \n",
    "    _subtable1_ = _subtable_\n",
    "    parent = bb.master_tree[parent]['parent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "bard",
   "language": "python",
   "name": "bard"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
